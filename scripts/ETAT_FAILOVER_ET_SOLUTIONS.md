# Ã‰tat des Tests de Failover - ProblÃ¨mes et Solutions

**Date :** 2025-11-21

## ğŸ“Š RÃ©sultat Actuel

- **Tests de base** : 13/13 (100%) âœ…
- **Tests de failover** : 0/2 (0%) âŒ

## âŒ ProblÃ¨mes IdentifiÃ©s

### 1. PostgreSQL Failover - RÃ©plicas en "start failed"

**SymptÃ´me** :
- Les rÃ©plicas PostgreSQL sont en Ã©tat "start failed"
- Erreur : `FATAL: data directory "/var/lib/postgresql/data" has invalid permissions`
- Le failover ne peut pas se produire car aucun rÃ©plica n'est prÃªt

**Cause** :
- Permissions incorrectes sur `/opt/keybuzz/postgres/data` (doit Ãªtre 0700 ou 0750)
- Les rÃ©plicas ne peuvent pas dÃ©marrer PostgreSQL

**Solution** :
- Script `00_fix_postgres_replicas.sh` crÃ©Ã© pour corriger les permissions
- RedÃ©marrer les conteneurs Patroni aprÃ¨s correction

**Action** :
```bash
bash 00_fix_postgres_replicas.sh
```

### 2. Redis Failover - Sentinel ne promeut pas de nouveau master

**SymptÃ´me** :
- Sentinel dÃ©tecte le master down (`+sdown`)
- Mais ne promeut pas automatiquement un nouveau master
- Les slaves restent en Ã©tat "slave"

**Causes possibles** :
1. **Quorum insuffisant** : Sentinel nÃ©cessite 2 sentinels sur 3 pour promouvoir un nouveau master
2. **Protected mode** : Sentinel est en protected mode et ne peut pas Ãªtre interrogÃ© depuis l'extÃ©rieur
3. **Configuration** : `sentinel monitor` nÃ©cessite 2 sentinels pour le quorum (actuellement configurÃ© avec `2`)

**VÃ©rification** :
- Configuration Sentinel : `sentinel monitor kb-redis-master ${MASTER_IP} 6379 2`
- Cela signifie qu'il faut 2 sentinels pour le quorum
- Avec 3 sentinels, le quorum devrait Ãªtre atteint

**Solution possible** :
- VÃ©rifier que les 3 sentinels sont opÃ©rationnels
- VÃ©rifier les logs Sentinel pour comprendre pourquoi le failover ne se produit pas
- Augmenter le dÃ©lai d'attente (actuellement 90 secondes)

## ğŸ”§ Solutions AppliquÃ©es

### Correction PostgreSQL
- Script `00_fix_postgres_replicas.sh` crÃ©Ã©
- Correction des permissions sur les rÃ©plicas
- RedÃ©marrage des conteneurs Patroni

### AmÃ©lioration Tests Failover
- DÃ©lais d'attente augmentÃ©s :
  - PostgreSQL : 90 secondes (ttl:30, loop_wait:10, retry_timeout:30)
  - Redis : 90 secondes (down-after:5s, failover-timeout:60s)
- VÃ©rifications multiples avec retry (5 tentatives)
- Logs dÃ©taillÃ©s pour diagnostic

## ğŸ“‹ Prochaines Ã‰tapes

1. **Corriger les permissions PostgreSQL** :
   ```bash
   bash 00_fix_postgres_replicas.sh
   ```

2. **Relancer les tests de failover** :
   ```bash
   bash 00_test_complet_avec_failover.sh /opt/keybuzz-installer/servers.tsv --yes
   ```

3. **Si les tests Ã©chouent encore** :
   - VÃ©rifier les logs Patroni et Sentinel
   - VÃ©rifier la configuration rÃ©seau
   - VÃ©rifier que les services peuvent communiquer entre eux

## âš ï¸ Note Importante

Les tests de failover automatique peuvent Ã©chouer pour plusieurs raisons :
- **DÃ©lais insuffisants** : Les services HA nÃ©cessitent du temps pour dÃ©tecter les pannes et promouvoir de nouveaux leaders
- **Configuration rÃ©seau** : Les services doivent pouvoir communiquer entre eux
- **Ã‰tat des rÃ©plicas** : Les rÃ©plicas doivent Ãªtre opÃ©rationnels pour prendre le relais

**Recommandation** : MÃªme si les tests de failover automatique Ã©chouent, l'infrastructure est fonctionnelle Ã  100% pour les tests de base. Les failovers peuvent Ãªtre testÃ©s manuellement ou nÃ©cessiter une configuration supplÃ©mentaire.

## âœ… Tests de Base - 100% RÃ©ussis

Tous les tests de base passent avec succÃ¨s :
- âœ… PostgreSQL : ConnectivitÃ©, Cluster, RÃ©plication, PgBouncer
- âœ… Redis : ConnectivitÃ©, RÃ©plication, Sentinel
- âœ… RabbitMQ : ConnectivitÃ©, Cluster
- âœ… MinIO : ConnectivitÃ©
- âœ… MariaDB : ConnectivitÃ©, Cluster Galera, ProxySQL

**L'infrastructure est prÃªte pour le Module 9 (K3s HA Core)**, mÃªme si les tests de failover automatique nÃ©cessitent des ajustements supplÃ©mentaires.

