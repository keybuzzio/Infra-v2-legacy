# Rapport Technique Complet : Migration Flannel â†’ Calico IPIP

**Date** : 2025-11-24  
**Contexte** : Module 10 - DÃ©ploiement Platform KeyBuzz (API, UI, My Portal)  
**Infrastructure** : K3s HA sur Hetzner Cloud (8 nÅ“uds : 3 masters + 5 workers)  
**ProblÃ¨me Initial** : Erreurs 503 Service Temporarily Unavailable sur toutes les URLs

---

## ğŸ“‹ Table des MatiÃ¨res

1. [ProblÃ¨me Initial](#problÃ¨me-initial)
2. [Diagnostic](#diagnostic)
3. [Solution ProposÃ©e](#solution-proposÃ©e)
4. [ImplÃ©mentation](#implÃ©mentation)
5. [ProblÃ¨mes RencontrÃ©s](#problÃ¨mes-rencontrÃ©s)
6. [Ã‰tat Actuel](#Ã©tat-actuel)
7. [Solutions ProposÃ©es](#solutions-proposÃ©es)
8. [Questions pour ChatGPT](#questions-pour-chatgpt)

---

## ğŸ”´ ProblÃ¨me Initial

### SymptÃ´mes

1. **Erreurs 503 Service Temporarily Unavailable** sur les 3 URLs :
   - `https://platform.keybuzz.io`
   - `https://platform-api.keybuzz.io`
   - `https://my.keybuzz.io`

2. **Pods en Ã©tat Running** mais inaccessibles :
   ```bash
   kubectl get pods -n keybuzz
   # Tous les pods sont Running (1/1)
   # keybuzz-api-* : 3 pods Running
   # keybuzz-ui-* : 3 pods Running
   # keybuzz-my-ui-* : 3 pods Running
   ```

3. **Services ClusterIP non fonctionnels** :
   ```bash
   kubectl get svc -n keybuzz
   # Services crÃ©Ã©s mais inaccessibles
   # keybuzz-api: ClusterIP 10.43.92.243:8080
   # keybuzz-ui: ClusterIP 10.43.102.230:80
   # keybuzz-my-ui: ClusterIP 10.43.232.70:80
   ```

---

## ğŸ” Diagnostic

### Tests de ConnectivitÃ© EffectuÃ©s

#### 1. Test Services ClusterIP depuis un Pod

```bash
kubectl exec -n keybuzz keybuzz-api-xxx -- curl http://10.43.92.243:8080/health
# RÃ©sultat : Timeout aprÃ¨s 2+ minutes
```

**Conclusion** : Les Services ClusterIP ne sont pas routables.

#### 2. Test ConnectivitÃ© IPs Pods Directes

```bash
# IPs des pods API
kubectl get pods -n keybuzz -l app=platform-api -o jsonpath='{.items[*].status.podIP}'
# RÃ©sultat : 10.42.5.5 10.42.7.7 10.42.9.4

# Test depuis l'Ingress NGINX (hostNetwork=true)
kubectl exec -n ingress-nginx nginx-ingress-controller-xxx -- curl http://10.42.5.5:8080/health
# RÃ©sultat : Timeout aprÃ¨s 5 secondes
```

**Conclusion** : Le rÃ©seau overlay (flannel) ne fonctionne pas.

#### 3. Test CoreDNS

```bash
# CoreDNS Ã©tait en CrashLoopBackOff (corrigÃ© depuis)
kubectl get pods -n kube-system | grep coredns
# Maintenant : Running

# Test rÃ©solution DNS
kubectl exec -n keybuzz test-pod -- nslookup keybuzz-api.keybuzz.svc.cluster.local
# RÃ©sultat : connection timed out; no servers could be reached
```

**Conclusion** : CoreDNS ne peut pas Ãªtre atteint car il utilise aussi le rÃ©seau overlay.

#### 4. Test Services NodePort

```bash
# Conversion en NodePort
kubectl patch svc keybuzz-api -n keybuzz --type='json' -p='[{"op":"replace","path":"/spec/type","value":"NodePort"}]'
# NodePort 30080 crÃ©Ã©

# Test depuis un nÅ“ud worker
ssh root@10.0.0.110 'curl http://localhost:30080/health'
# RÃ©sultat : Timeout
```

**Conclusion** : Les NodePorts ne fonctionnent pas non plus.

### Cause Racine IdentifiÃ©e

**VXLAN bloquÃ© sur Hetzner Cloud** :
- Hetzner Cloud bloque le port UDP 8472 utilisÃ© par VXLAN
- Flannel (CNI par dÃ©faut de K3s) utilise VXLAN pour crÃ©er le rÃ©seau overlay
- Sans VXLAN, le rÃ©seau overlay ne peut pas fonctionner

**Impact** :
- âŒ Services ClusterIP : Non fonctionnels (routage via kube-proxy nÃ©cessite le rÃ©seau overlay)
- âŒ Services NodePort : Non fonctionnels (mÃªme raison)
- âŒ Communication inter-pods via IPs overlay : Non fonctionnelle
- âŒ CoreDNS : Ne peut pas Ãªtre atteint via le rÃ©seau overlay

**Architecture Actuelle (CassÃ©e)** :
```
Ingress NGINX (hostNetwork=true) 
  â†’ Essaie d'atteindre Service ClusterIP (10.43.x.x)
    â†’ kube-proxy doit router via rÃ©seau overlay
      â†’ VXLAN bloquÃ© â†’ Ã‰chec
```

---

## âœ… Solution ProposÃ©e

### Solution DÃ©finitive : Calico IPIP

**Principe** : Remplacer Flannel (VXLAN) par Calico (IPIP)

**Pourquoi Calico IPIP ?**
- âœ… IPIP fonctionne sur Hetzner Cloud (pas de port bloquÃ©)
- âœ… RÃ©seau overlay pleinement fonctionnel
- âœ… Services ClusterIP opÃ©rationnels
- âœ… CoreDNS accessible
- âœ… Compatible avec Deployments classiques
- âœ… Scalable (HPA, multi-replicas)
- âœ… Architecture Kubernetes native

**Architecture Cible** :
```
Ingress NGINX (DaemonSet + hostNetwork=true)
  â†“
Services ClusterIP (10.43.x.x) - Fonctionnels
  â†“
Calico IPIP Overlay Network
  â†“
Pods (10.42.x.x) - Deployments classiques
```

**Avantages** :
- âœ… Pas de hostNetwork sur les apps
- âœ… Pas de conflits de ports
- âœ… Scaling horizontal possible
- âœ… HPA fonctionnel
- âœ… Multi-tenant compatible
- âœ… Architecture Kubernetes standard

---

## ğŸ”§ ImplÃ©mentation

### Ã‰tape 1 : DÃ©sactiver Flannel

**Action** : Modifier `/etc/rancher/k3s/config.yaml` sur tous les masters

```yaml
flannel-backend: none
disable-network-policy: true
```

**RÃ©sultat** : âœ… Configuration appliquÃ©e sur les 3 masters (k3s-master-01, k3s-master-02, k3s-master-03)

### Ã‰tape 2 : RedÃ©marrer K3s

**Action** : `systemctl restart k3s` sur tous les masters

**RÃ©sultat** : âœ… K3s redÃ©marrÃ©, cluster accessible aprÃ¨s 60 secondes

### Ã‰tape 3 : Installer Calico

**Action** :
```bash
kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/calico.yaml
```

**RÃ©sultat** : âœ… Calico installÃ©, 8 pods dÃ©ployÃ©s (un par nÅ“ud)

### Ã‰tape 4 : Configurer Calico en Mode IPIP

**Action** : Patcher le DaemonSet Calico pour :
- `CALICO_IPV4POOL_IPIP: Always`
- `CALICO_IPV4POOL_VXLAN: Never`

**RÃ©sultat** : âœ… Configuration IPIP appliquÃ©e

### Ã‰tape 5 : VÃ©rification Configuration

**VÃ©rifications effectuÃ©es** :
- âœ… IPPool configurÃ© : `ipipMode: Always`, `vxlanMode: Never`
- âœ… 8 IPAMBlocks crÃ©Ã©s (un par nÅ“ud)
- âœ… BGP peering Ã©tabli : 7/8 nÅ“uds connectÃ©s

---

## âš ï¸ ProblÃ¨mes RencontrÃ©s

### ProblÃ¨me 1 : Conflit nftables/iptables

#### SymptÃ´me

```
[ERROR] felix/table.go 881: iptables-save failed because there are incompatible nft rules in the table. 
Remove the nft rules to continue. ipVersion=0x4 table="filter"
```

#### Cause

Des rÃ¨gles nftables sont prÃ©sentes sur les nÅ“uds et bloquent l'utilisation d'iptables par Calico Felix.

#### Solution AppliquÃ©e

**Action** : Supprimer les rÃ¨gles nftables sur tous les nÅ“uds

```bash
for ip in 10.0.0.100 10.0.0.101 10.0.0.102 10.0.0.110 10.0.0.111 10.0.0.112 10.0.0.113 10.0.0.114; do
  ssh root@$ip "nft flush ruleset 2>/dev/null || true"
done
```

**RÃ©sultat** : âœ… RÃ¨gles nftables supprimÃ©es sur tous les nÅ“uds

**Script crÃ©Ã©** : `fix_calico_ipset_nft.sh` pour automatiser cette correction

### ProblÃ¨me 2 : ipset manquant/incompatible

#### SymptÃ´me

```
[ERROR] felix/ipsets.go 599: Bad return code from 'ipset list'. 
error=exit status 1 family="inet" 
stderr="ipset v7.11: Kernel and userspace incompatible: 
settype hash:ip with revision 6 not supported by userspace."
```

#### Cause

1. **ipset manquant** : ipset n'Ã©tait pas installÃ© sur la plupart des nÅ“uds
2. **Version incompatible** : Certains nÅ“uds ont ipset v7.11 qui ne supporte pas la rÃ©vision 6 de `hash:ip` requise par le kernel

#### Solution AppliquÃ©e

**Action 1** : Installer ipset sur tous les nÅ“uds

```bash
for ip in 10.0.0.100 10.0.0.101 10.0.0.102 10.0.0.110 10.0.0.111 10.0.0.112 10.0.0.113 10.0.0.114; do
  ssh root@$ip "apt-get update && apt-get install ipset -y"
done
```

**RÃ©sultat** : âœ… ipset installÃ© sur tous les nÅ“uds

**Action 2** : VÃ©rifier les versions

- k3s-master-01 : ipset v7.19 âœ… (compatible)
- Autres nÅ“uds : ipset v7.11 âŒ (incompatible)

**ProblÃ¨me restant** : Certains nÅ“uds ont toujours ipset v7.11 qui ne supporte pas la rÃ©vision 6.

#### Solutions ProposÃ©es (Non AppliquÃ©es)

1. **Mettre Ã  jour ipset vers v7.19** sur tous les nÅ“uds :
   ```bash
   apt-get update
   apt-get install --only-upgrade ipset
   ```

2. **DÃ©sactiver ipset dans Calico** (workaround) :
   ```bash
   kubectl patch felixconfiguration default --type merge -p '{
     "spec": {
       "ipsetsRefreshInterval": "0s"
     }
   }'
   ```
   **Note** : Peut affecter les performances.

3. **Downgrade vers Calico v3.26** (compatible avec ipset v7.11)

### ProblÃ¨me 3 : Felix en "wait-for-ready"

#### SymptÃ´me

```
calico/node is not ready: felix is not ready: readiness probe reporting 503
```

Tous les pods Calico restent en `0/1 Ready` (Running mais pas prÃªts).

#### Cause

Felix ne peut pas terminer son initialisation Ã  cause des erreurs ipset et nftables.

#### Ã‰tat Actuel

- **Pods Calico Ready** : 3/8 (aprÃ¨s corrections nftables et installation ipset)
- **BGP Peering** : 7/8 nÅ“uds connectÃ©s âœ…
- **Felix Status** : Toujours en "wait-for-ready" sur certains nÅ“uds

---

## ğŸ“Š Ã‰tat Actuel

### Pods Calico

```bash
kubectl get pods -n kube-system -l k8s-app=calico-node
```

**RÃ©sultat** :
- 3/8 pods sont `1/1 Ready`
- 5/8 pods sont `0/1 Running` (pas prÃªts)

### Services ClusterIP

**Test depuis un pod KeyBuzz** :
```bash
kubectl exec -n keybuzz keybuzz-api-xxx -- curl http://10.43.92.243:8080/health
# RÃ©sultat : âœ… "healthy"
```

**Test depuis Ingress NGINX** :
```bash
kubectl exec -n ingress-nginx nginx-ingress-controller-xxx -- curl http://keybuzz-api.keybuzz.svc.cluster.local:8080/health
# RÃ©sultat : âŒ Timeout / Could not resolve host
```

**Conclusion** : Le Service ClusterIP fonctionne depuis un pod, mais pas depuis l'Ingress (problÃ¨me DNS).

### DNS

**Test rÃ©solution DNS** :
```bash
kubectl run test-dns --image=busybox:1.36 --rm -it --restart=Never -- nslookup keybuzz-api.keybuzz.svc.cluster.local
# RÃ©sultat : âŒ "connection timed out; no servers could be reached"
```

**Conclusion** : CoreDNS ne rÃ©pond pas aux requÃªtes DNS.

### URLs Externes

**Test** :
```bash
curl -k https://platform.keybuzz.io
curl -k https://platform-api.keybuzz.io/health
curl -k https://my.keybuzz.io
```

**RÃ©sultat** : âŒ 503 Service Temporarily Unavailable

**Conclusion** : Les URLs externes ne fonctionnent toujours pas.

### Configuration Calico

**IPPool** :
```yaml
spec:
  ipipMode: Always
  vxlanMode: Never
  cidr: 192.168.0.0/16
  natOutgoing: true
```

**IPAMBlocks** : 8 blocks crÃ©Ã©s (un par nÅ“ud) âœ…

**BGP** : 7/8 nÅ“uds avec peering Ã©tabli âœ…

---

## ğŸ’¡ Solutions ProposÃ©es

### Solution 1 : Mettre Ã  jour ipset vers v7.19 (RecommandÃ©)

**Action** : Mettre Ã  jour ipset sur tous les nÅ“uds qui ont encore v7.11

```bash
for ip in 10.0.0.101 10.0.0.102 10.0.0.110 10.0.0.111 10.0.0.112 10.0.0.113 10.0.0.114; do
  ssh root@$ip "apt-get update && apt-get install --only-upgrade ipset -y"
done
```

**Puis** : RedÃ©marrer les pods Calico
```bash
kubectl delete pod -n kube-system -l k8s-app=calico-node
```

**Avantages** :
- âœ… RÃ©sout le problÃ¨me ipset Ã  la source
- âœ… Pas d'impact sur les performances
- âœ… Solution dÃ©finitive

**InconvÃ©nients** :
- âš ï¸ NÃ©cessite un accÃ¨s SSH Ã  tous les nÅ“uds
- âš ï¸ Peut nÃ©cessiter un redÃ©marrage des pods Calico

### Solution 2 : DÃ©sactiver ipset dans Calico (Workaround)

**Action** : Configurer Felix pour ne pas utiliser ipset

```bash
kubectl patch felixconfiguration default --type merge -p '{
  "spec": {
    "ipsetsRefreshInterval": "0s",
    "ipSetRefreshInterval": "0s"
  }
}'
```

**Avantages** :
- âœ… Solution rapide
- âœ… Pas besoin d'accÃ¨s SSH aux nÅ“uds

**InconvÃ©nients** :
- âš ï¸ Peut affecter les performances de Calico
- âš ï¸ Certaines fonctionnalitÃ©s peuvent ne pas fonctionner
- âš ï¸ Solution temporaire, pas dÃ©finitive

### Solution 3 : Downgrade vers Calico v3.26

**Action** : Remplacer Calico v3.27 par v3.26

```bash
kubectl delete -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/calico.yaml
kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.5/manifests/calico.yaml
```

**Puis** : Reconfigurer IPIP comme prÃ©cÃ©demment.

**Avantages** :
- âœ… Compatible avec ipset v7.11
- âœ… Pas besoin de mettre Ã  jour ipset

**InconvÃ©nients** :
- âš ï¸ Version plus ancienne (moins de fonctionnalitÃ©s)
- âš ï¸ NÃ©cessite de rÃ©installer Calico

### Solution 4 : Attendre que Calico termine son initialisation

**Action** : Attendre 10-20 minutes supplÃ©mentaires

**Raison** : Felix peut prendre du temps pour terminer sa configuration, mÃªme avec des erreurs ipset.

**Avantages** :
- âœ… Pas d'action requise
- âœ… Peut rÃ©soudre le problÃ¨me naturellement

**InconvÃ©nients** :
- âš ï¸ Pas garanti que cela rÃ©solve le problÃ¨me
- âš ï¸ Les erreurs ipset peuvent persister

---

## â“ Questions pour ChatGPT

### Question 1 : CompatibilitÃ© ipset

**Contexte** : Certains nÅ“uds ont ipset v7.11 qui ne supporte pas la rÃ©vision 6 de `hash:ip` requise par le kernel. D'autres nÅ“uds ont ipset v7.19 qui fonctionne.

**Questions** :
1. Calico peut-il fonctionner avec un mÃ©lange de versions ipset sur diffÃ©rents nÅ“uds ?
2. Est-il possible de configurer Calico pour qu'il fonctionne avec ipset v7.11 ?
3. Y a-t-il une configuration Felix qui permet de contourner le problÃ¨me ipset ?

### Question 2 : DNS et CoreDNS

**Contexte** : CoreDNS est Running mais ne rÃ©pond pas aux requÃªtes DNS. Les pods ne peuvent pas rÃ©soudre les noms de services.

**Questions** :
1. Pourquoi CoreDNS ne rÃ©pond pas malgrÃ© le fait qu'il soit Running ?
2. Y a-t-il une relation entre les erreurs ipset et le dysfonctionnement de CoreDNS ?
3. Comment diagnostiquer et corriger le problÃ¨me DNS dans ce contexte ?

### Question 3 : Services ClusterIP depuis Ingress

**Contexte** : Le Service ClusterIP fonctionne depuis un pod KeyBuzz (`healthy`), mais l'Ingress NGINX ne peut pas y accÃ©der (timeout / DNS resolution failed).

**Questions** :
1. Pourquoi l'Ingress NGINX (hostNetwork=true) ne peut pas accÃ©der aux Services ClusterIP alors qu'un pod normal peut ?
2. Y a-t-il une configuration spÃ©cifique nÃ©cessaire pour que l'Ingress puisse accÃ©der aux Services ClusterIP avec Calico ?
3. Le problÃ¨me vient-il du DNS ou du routage rÃ©seau ?

### Question 4 : StratÃ©gie de Correction

**Contexte** : Nous avons 3/8 pods Calico Ready, des erreurs ipset persistantes, et le rÃ©seau ne fonctionne toujours pas complÃ¨tement.

**Questions** :
1. Quelle est la meilleure stratÃ©gie pour rÃ©soudre ce problÃ¨me : mettre Ã  jour ipset, dÃ©sactiver ipset, ou downgrade Calico ?
2. Est-il normal que seulement 3/8 pods Calico soient Ready aprÃ¨s 1 heure d'attente ?
3. Y a-t-il d'autres problÃ¨mes que nous n'avons pas identifiÃ©s qui pourraient bloquer Calico ?

### Question 5 : Alternative Ã  Calico

**Contexte** : Calico rencontre des problÃ¨mes de compatibilitÃ© avec ipset et nftables.

**Questions** :
1. Y a-t-il une alternative Ã  Calico qui fonctionnerait mieux sur Hetzner Cloud avec K3s ?
2. Cilium serait-il une meilleure option ? Quels sont les avantages/inconvÃ©nients ?
3. Est-il possible de faire fonctionner Flannel sans VXLAN (mode host-gw) ?

### Question 6 : Diagnostic ComplÃ©mentaire

**Contexte** : Nous avons fait beaucoup de tests mais le problÃ¨me persiste.

**Questions** :
1. Quels autres diagnostics devrions-nous effectuer pour identifier la cause racine ?
2. Y a-t-il des logs spÃ©cifiques Ã  vÃ©rifier que nous n'avons pas encore consultÃ©s ?
3. Comment vÃ©rifier si le routage IPIP fonctionne correctement entre les nÅ“uds ?

---

## ğŸ“ Commandes de Diagnostic Utiles

### VÃ©rifier l'Ã©tat Calico

```bash
# Ã‰tat des pods
kubectl get pods -n kube-system -l k8s-app=calico-node -o wide

# Logs Calico
kubectl logs -n kube-system -l k8s-app=calico-node --tail=50 | grep -E 'ERROR|WARN|ready'

# Readiness probe
kubectl exec -n kube-system calico-node-xxx -- /bin/calico-node -felix-ready -bird-ready
```

### VÃ©rifier le routage

```bash
# Routes depuis un pod
kubectl exec -n keybuzz keybuzz-api-xxx -- ip route

# Test connectivitÃ© Pod-to-Pod
kubectl exec -n keybuzz keybuzz-api-xxx -- ping -c 2 10.42.5.5

# Test Service ClusterIP
kubectl exec -n keybuzz keybuzz-api-xxx -- curl http://10.43.92.243:8080/health
```

### VÃ©rifier DNS

```bash
# Test rÃ©solution DNS
kubectl run test-dns --image=busybox:1.36 --rm -it --restart=Never -- nslookup keybuzz-api.keybuzz.svc.cluster.local

# Logs CoreDNS
kubectl logs -n kube-system -l k8s-app=kube-dns --tail=50

# Configuration CoreDNS
kubectl get configmap -n kube-system coredns -o yaml
```

### VÃ©rifier ipset

```bash
# Version ipset sur chaque nÅ“ud
for ip in 10.0.0.100 10.0.0.101 10.0.0.102 10.0.0.110 10.0.0.111 10.0.0.112 10.0.0.113 10.0.0.114; do
  echo "$ip:"
  ssh root@$ip "ipset --version 2>&1 | head -1"
done
```

---

## ğŸ“š RÃ©fÃ©rences

- **Calico Documentation** : https://docs.tigera.io/calico/latest/getting-started/kubernetes/requirements
- **Calico IPIP Mode** : https://docs.tigera.io/calico/latest/networking/configuring/vxlan-ipip
- **Calico Troubleshooting** : https://docs.tigera.io/calico/latest/operations/troubleshooting/
- **K3s Network Configuration** : https://docs.k3s.io/networking
- **Hetzner Cloud Network Limitations** : Port UDP 8472 bloquÃ© (VXLAN)
- **ipset Compatibility** : https://ipset.netfilter.org/ipset.man.html

---

## ğŸ¯ RÃ©sumÃ© ExÃ©cutif

**ProblÃ¨me Initial** : VXLAN bloquÃ© sur Hetzner Cloud â†’ Flannel non fonctionnel â†’ RÃ©seau overlay cassÃ© â†’ Erreurs 503

**Solution AppliquÃ©e** : Migration vers Calico IPIP

**ProblÃ¨mes RencontrÃ©s** :
1. âœ… Conflit nftables/iptables â†’ RÃ©solu (rÃ¨gles nftables supprimÃ©es)
2. âš ï¸ ipset manquant/incompatible â†’ Partiellement rÃ©solu (installÃ© mais versions mixtes)
3. âš ï¸ Felix en "wait-for-ready" â†’ En cours (3/8 pods Ready)

**Ã‰tat Actuel** :
- âœ… Calico installÃ© et configurÃ© (IPIP mode)
- âœ… BGP peering Ã©tabli (7/8 nÅ“uds)
- âš ï¸ 3/8 pods Calico Ready
- âš ï¸ Erreurs ipset persistantes
- âŒ DNS ne fonctionne pas
- âŒ Ingress ne peut pas accÃ©der aux Services ClusterIP
- âŒ Erreurs 503 toujours prÃ©sentes

**Prochaines Ã‰tapes RecommandÃ©es** :
1. Mettre Ã  jour ipset vers v7.19 sur tous les nÅ“uds
2. RedÃ©marrer les pods Calico
3. VÃ©rifier que tous les pods Calico passent en Ready
4. Tester DNS et Ingress

---

---

## ğŸ¯ VERDICT FINAL (ChatGPT Expert KeyBuzz)

### Diagnostic Final

**Ã‰tat Actuel** :
- âŒ Flannel (VXLAN) : CassÃ© (bloquÃ© par Hetzner)
- âŒ Calico (IPIP) : CassÃ© (incompatibilitÃ© ipset/kernel)
- âŒ DNS : CassÃ©
- âŒ Services ClusterIP : CassÃ©s
- âŒ Ingress : Ne peut plus joindre l'overlay

**Cause Racine Unique** :
```
ipset v7.11: Kernel and userspace incompatible: 
settype hash:ip with revision 6 not supported by userspace.
```

**Conclusion** : 
- âŒ **Calico NE PEUT PAS FONCTIONNER** sur des nÅ“uds avec ipset v7.11
- âŒ Erreur FATALE, bloquante, NON contournable sans upgrade OS
- âŒ MÃªme avec patches Felix, dÃ©sactivation ipset, suppression nftables â†’ Ã©tat bancal
- âŒ Calico ne fonctionnera jamais proprement sur ce cluster

**Verdict** : **ARRÃŠTER la migration Calico MAINTENANT**

### Solution DÃ©finitive : Cilium

**Pourquoi Cilium ?**
- âœ… Ne dÃ©pend PAS d'ipset
- âœ… N'utilise PAS VXLAN par dÃ©faut
- âœ… Pas d'iptables/nftables
- âœ… Pas d'IPIP
- âœ… Utilise eBPF du kernel (compatible 100% avec kernels Hetzner)
- âœ… Performances maximales
- âœ… Stable + moderne
- âœ… RecommandÃ© pour infrastructures Kubernetes modernes

**Configuration Cilium** :
- Mode : `tunneling=disabled` + `kube-proxy-replacement=strict`
- Pas de VXLAN, pas d'IPIP, pas d'IPSet, pas d'iptables, pas de nftables
- Compatible 100% avec kernels Hetzner

**Plan d'Action** :
1. Purger Calico proprement
2. RÃ©activer Flannel temporairement (pour stabilitÃ©)
3. Installer Cilium (tunnel=disabled)
4. VÃ©rifications
5. Reprendre Module 10

---

**Document crÃ©Ã© le** : 2025-11-24  
**Auteur** : Auto (Agent IA)  
**Statut** : âœ… Verdict final reÃ§u - Migration vers Cilium recommandÃ©e  
**PrioritÃ©** : CRITIQUE - Bloque le dÃ©ploiement du Module 10

